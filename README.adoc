= Street Java Demo Script
include::_attributes.adoc[]

This is demo script of:

image::street-java-logo.svg[Street Java Logo,400]

:toc:

[#installation]
== Install ArgoCD, Pipelines and Quay using the operators

Install ArgoCD Operator, Openshift Pipelines and Quay (simplified non-supported configuration). Log in as cluster-admin and run this command:

```sh
until oc apply -k util/bootstrap/; do sleep 2; done
```

[#preparation]
== Preparation

Go to link:https://api.slack.com/apps[api.slack.com/apps] and create a new app, call it `Street Java Receiver` for instance and choose a workspace to place it.

Then click on `Incoming Webhooks` activate the option and click on `Add New Webhook to Workspace` then choose a `channel`. Finally copy the `webhook` url and use it in the `.env` file you're about to create.

Create a `.env` in the folder where you have cloned this repository copy the next set of variables and fill the empty ones.

[source,sh,attributes]
----
export USERNAME=<FILL_ME/>
export PASSWORD=<FILL_ME/>

export PROJECT_NAME=street-java-${USERNAME}

export ADMIN_USER=<FILL_ME/>
export ADMIN_PASSWORD=<FILL_ME/>

export CLUSTER_DOMAIN=<FILL_ME/>
export SERVER=https://api.${CLUSTER_DOMAIN}:6443

export SLACK_WEBHOOK=<FILL_ME/>
export SLACK_CHANNEL=<FILL_ME/>

export REPOSITORY="image-registry.openshift-image-registry.svc:5000/${PROJECT_NAME}/fruit-gateway"
export TAG=1.0.0-SNAPSHOT
----

Open three terminal windows, referred to as *T1*, *T2* and *T3* and change to the folder where this repository has been cloned.

Run this command in *T1*:

[.console-input]
[source,bash, subs="+attributes"]
----
. .env

oc login -u ${ADMIN_USER} -p ${ADMIN_PASSWORD} --insecure-skip-tls-verify=true --server=${SERVER}
sudo cp ~/.kube/config /var/root/.kube/config
----

Run this command in *T2* and *T3* before running the demo:

[.console-input]
[source,bash, subs="+attributes"]
----
. .env

export KUBECONFIG=~/.kube/config-street-java-user

oc login -u ${USERNAME} -p ${PASSWORD} --server=${SERVER} --insecure-skip-tls-verify=true

oc project ${PROJECT_NAME}
----

Run this command in *T2* to create a resource quota limiting the number of `Deployments` this way you will show one of the typical problems a developer has to face in a kubernetes cluster.

[source,sh,attributes]
----
oc apply -n ${PROJECT_NAME} -f - <<EOF
kind: ResourceQuota
apiVersion: v1
metadata:
    name: guide-resource-quota
spec:
  hard:
    count/deployments.apps: '2'
EOF
----

[#checking-in]
== Checking in 

You've been assigned the task of developing a gateway and UI for a backend that's already been developed and is deployed as a Helm chart. Eventually you will also deploy your application as part of the same chart, as a dependency.

Go to *T2* and deploy the chart.

NOTE: The chart already contains fruit-gateway but we're going to fake it's not developed yet by disabling it.

[source,sh,attributes]
----
helm install --set fruit-gateway.enabled=false street-java helm/street-java
----

Open the web console and log in with the non-admin user and open the topology view.

[#round-1]
== Round 1 - Fight in localhost

We're going to run our gateway locally first, hence localhost.

Go to *T3* and:

[source,sh,attributes]
----
cd fruit-gateway
----

Run the quarkus app in dev mode... show the UI, it fails... no problem, it's just to show how we start developing our gateway.

[source,sh,attributes]
----
mvn quarkus:dev
----

[#round-2]
== Round 2 - Fight in two places at the same time 

Now we have evolved and want to use `fruit-service` running in our project and `jaeger` in namespace `street-java-infra`. Show the app working... connecting to fruit-service running in the cluster... and also show jaeger running in OpenShift.
 
NOTE: We run in the production profile because we have port-forwarded the services and are available locally!

NOTE: Mention that jaeger is installed via operator and supported

Go to *T1* and run this command that will port-forward all services in ${PROJECT} and street-java-infra in bulk and change `/etc/hosts`

NOTE: Wait until fruit-service is been deployed.

NOTE: Explain what kubefwd does...

[source,sh,attributes]
----
sudo kubefwd svc -n ${PROJECT_NAME} -n street-java-infra
----

In *T3*:

[source,sh,attributes]
----
mvn quarkus:dev -Dquarkus.profile=prod
----

Open jaeger from *T2*:

[source,sh,attributes]
----
open https://$(oc get route jaeger-all-in-one-inmemory -n street-java-infra -o jsonpath='{.spec.host}')
----

[#round-3]
== Round 3 - Flying Kick to OCP

Type 'q' in *T3* and deploy our app directly from quarkus, using the openshift extension:

NOTE: Don't wait wait too much, and look at BuildConfig and Build.

[source,sh,attributes]
----
mvn package -DskipTests -Dquarkus.kubernetes.deploy=true
----

Run this command to see that the problems is related to LimitRanges...  

[source,sh,attributes]
----
oc get events --sort-by='.metadata.creationTimestamp' | grep Failed
----

Show the limit with this command o in the web console:

[source,sh,attributes]
----
oc get limitranges -o yaml
----

And delete it!

[source,sh,attributes]
----
oc delete limitrange/guide-resource-limits
----

Try again... and wait until it fails.

[source,sh,attributes]
----
mvn package -DskipTests -Dquarkus.kubernetes.deploy=true
----

This time it will fail because there is a quota limiting the number of deployments to 2.

[source,sh,attributes]
----
oc get resourcequota/guide-resource-quota
----

Run this command to increase quota to 5 deployments:

[source,sh,attributes]
----
oc patch  resourcequota/guide-resource-quota  -p '{"spec" : { "hard" : {  "count/deployments.apps" : "5" } } }'
----

Make a change in `fruit-gateway/src/main/webapp/src/App.js` line 61.

[source,html,attributes]
----
<Col><h1>Street Java Status!!!</h1></Col>
----

Try again, this time it should work. 

[source,sh,attributes]
----
mvn package -DskipTests -Dquarkus.kubernetes.deploy=true
----

Go to the webconsole and show the results...

[#round-4]
== Round 4 - Hit'em with the helm!

The idea is to deploy our app with a helm chart...

Before delete all the resources created... from *T3*.

[source,sh,attributes]
----
oc delete -f ./target/kubernetes/openshift.yml
----

And upgrade the helm chart setting image repository and tag to the ones we had been using before from *T2*.

[source,sh,attributes]
----
echo "REPOSITORY=${REPOSITORY}"
echo "TAG=${TAG}"
helm upgrade \
  --set fruit-gateway.image.repository=${REPOSITORY} \
  --set fruit-gateway.image.tag=${TAG} \
 street-java helm/street-java
----

[#round-5]
== Round 5 - Fighting at the Quay

Make a change in `fruit-gateway/src/main/webapp/src/App.js` line 61.

[source,html,attributes]
----
<Col><h1>Street Java Status!!!</h1></Col>
----

Then from *T2*:

[source,sh,attributes]
----
./fruit-gateway/image-build.sh
----

Login in the enterprise Quay registry.

[source,sh,attributes]
----
export REGISTRY=$(oc get route myregistry-quay -n quay-system -o jsonpath='{.spec.host}')
podman login -u ${USERNAME} -p openshift --tls-verify=false ${REGISTRY}
----

Prepare image name and tag:

[source,sh,attributes]
----
export PROJECT_ID=street-java
export ARTIFACT_VERSION=$(mvn -f fruit-gateway/pom.xml help:evaluate -Dexpression=project.version -q -DforceStdout)
export ARTIFACT_ID=$(mvn -f fruit-gateway/pom.xml help:evaluate -Dexpression=project.artifactId -q -DforceStdout)
export GIT_HASH=$(git rev-parse HEAD)
----

Push the image:

[source,sh,attributes]
----
podman tag localhost/${PROJECT_ID}-${ARTIFACT_ID}:${GIT_HASH} ${REGISTRY}/${USERNAME}/${PROJECT_ID}-${ARTIFACT_ID}:${GIT_HASH}
podman push --tls-verify=false ${REGISTRY}/${USERNAME}/${PROJECT_ID}-${ARTIFACT_ID}:${GIT_HASH}
----

Get the image digest:

[source,sh,attributes]
----
export IMAGE_DIGEST_RAW=$(skopeo inspect --tls-verify=false docker://${REGISTRY}/${USERNAME}/${PROJECT_ID}-${ARTIFACT_ID}:${GIT_HASH} | jq -r .Digest)
export IMAGE_DIGEST=${IMAGE_DIGEST_RAW:7}
echo "IMAGE_DIGEST = ${IMAGE_DIGEST}"
----

Let's upgrade, *this time to use the image in the enterprise registry*:

[source,sh,attributes]
----
helm upgrade \
  --set fruit-gateway.image.repository=${REGISTRY}/${USERNAME}/${PROJECT_ID}-${ARTIFACT_ID}@sha256 \
  --set fruit-gateway.image.tag=${IMAGE_DIGEST} \
 street-java helm/street-java
----

Run this command to see that the problems is related to permissions in the enterprise registry...  

[source,sh,attributes]
----
oc get events --sort-by='.metadata.creationTimestamp' | grep Failed
----

Open quay from *T2* and create a robot account called `cicd`, give it `Read` permission on the `street-java-fruit-gateway` repository:

[source,sh,attributes]
----
open https://$(oc get route myregistry-quay -n quay-system -o jsonpath='{.spec.host}')
----

Paste the password of the robot account:

[source,sh,attributes]
----
export CONTAINER_REGISTRY_USERNAME="${USERNAME}+cicd"
echo "CONTAINER_REGISTRY_PASSWORD: " && read -s CONTAINER_REGISTRY_PASSWORD
----

Create the secret with the registry credentials of the robot account:

[source,sh,attributes]
----
oc create -n ${PROJECT_NAME} secret docker-registry street-java-pull-secret \
  --docker-server=https://${REGISTRY} \
  --docker-username=${CONTAINER_REGISTRY_USERNAME} \
  --docker-password=${CONTAINER_REGISTRY_PASSWORD}
----

New upgrade, this time with the name of the secret to be used!

[NOTE]
====
This is the relevant part this time, with it you set the name of the secret with the credentials to access the enterprise registry: 

[source,properties,attributes]
----
fruit-gateway.imagePullSecrets[0].name=street-java-pull-secret
----

====

[source,sh,attributes]
----
helm upgrade \
  --set fruit-gateway.image.repository=${REGISTRY}/${USERNAME}/${PROJECT_ID}-${ARTIFACT_ID}@sha256 \
  --set fruit-gateway.image.tag=${IMAGE_DIGEST} \
  --set fruit-gateway.imagePullSecrets[0].name=street-java-pull-secret \
 street-java helm/street-java
----

[#round-6]
== Round 6 - Setting ground rules

Let's check the status of the whole system through the `config` api exposed by our gateway. Although maybe you already notice errors in jaeger before... Use *T2* to run this command:

[source,attributes]
----
for i in {1..20}; do curl -s https://$(oc get route/fruit-gateway -o jsonpath='{.spec.host}')/api/config | jq .status.status ; done
----

This type or errors are not easy to detect, hence defining a behavior baseline will help us detecting abnormal situations. So measuring is key and Prometheus can help us with this.

Let's add an extension to help us generating Prometheus metrics. Run this in *T3*.

[source,sh,attributes]
----
mvn quarkus:add-extensions -Dextensions='micrometer-registry-prometheus'
----

Let's count errors in `fruit-gateway/src/main/java/com/redhat/fruit/gateway/ApiImpl.java`, to do so let's start by injecting the `MeterRegistry` with the following statement.

[source,java,attributes]
----
@Inject
MeterRegistry registry;
----

Then count error every time we set status as `DEGRADED`.

[source,java,attributes]
----
registry.counter(ACC_ERRORS_COUNT_NAME).increment();
----

As we did in before, let's test locally our changes from *T3*.

[source,java,attributes]
----
mvn quarkus:dev -Dquarkus.profile=prod
----

Let's be sure that there are some errors...

[source,attributes]
----
for i in {1..20}; do curl -s http://localhost:8080/api/config | jq .status.status ; done
----

Open the UI in http://localhost:8080 and run this command to see the count or errors:

[source,sh,attributes]
----
curl -s http://localhost:8080/q/metrics | grep -i acc_errors_count
----

[#round-7]
== Round 7 - Ground rules also apply to OCP!

You can stop quarkus dev with `q`. Now from *T2* let's build the new image locally:

[source,sh,attributes]
----
./fruit-gateway/image-build.sh
----

Push the image:

[source,sh,attributes]
----
podman tag localhost/${PROJECT_ID}-${ARTIFACT_ID}:${GIT_HASH} ${REGISTRY}/${USERNAME}/${PROJECT_ID}-${ARTIFACT_ID}:${GIT_HASH}
podman push --tls-verify=false ${REGISTRY}/${USERNAME}/${PROJECT_ID}-${ARTIFACT_ID}:${GIT_HASH}
----

Get the image digest:

[source,sh,attributes]
----
export IMAGE_DIGEST_RAW=$(skopeo inspect --tls-verify=false docker://${REGISTRY}/${USERNAME}/${PROJECT_ID}-${ARTIFACT_ID}:${GIT_HASH} | jq -r .Digest)
export IMAGE_DIGEST=${IMAGE_DIGEST_RAW:7}
echo "IMAGE_DIGEST_MONITORING = ${IMAGE_DIGEST}"
----

Let's upgrade, this time the image should expose metrics:

[source,sh,attributes]
----
helm upgrade \
  --set fruit-gateway.image.repository=${REGISTRY}/${USERNAME}/${PROJECT_ID}-${ARTIFACT_ID}@sha256 \
  --set fruit-gateway.image.tag=${IMAGE_DIGEST} \
  --set fruit-gateway.imagePullSecrets[0].name=street-java-pull-secret \
 street-java helm/street-java
----

Let's generate some traffic and errors...

[source,attributes]
----
for i in {1..20}; do curl -s https://$(oc get route/fruit-gateway -o jsonpath='{.spec.host}')/api/config | jq .status.status ; done
----

Now let's inspect metrics again:

[source,sh,attributes]
----
curl -s https://$(oc get route/fruit-gateway -o jsonpath='{.spec.host}')/q/metrics | grep -i acc_errors_count
----

[#round-8]
== Round 8 - Fighting along Prometheus

Now it's time to expose our metrics using a `ServiceMonitor` so that Prometheus for user defined project can scrape them.

From *T2*:

[source,sh,attributes]
----
oc apply -f - <<EOF
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  labels:
    k8s-app: prometheus
  name: fruit-gateway-monitor
  namespace: ${PROJECT_NAME}
spec:
  endpoints:
    - interval: 30s
      path: /q/metrics
      port: http
  namespaceSelector:
    matchNames:
    - ${PROJECT_NAME}
  selector:
    matchLabels:
      app.kubernetes.io/name: fruit-gateway
EOF
----

Give it 30 sec., then use this link to see our count of errors.

[source,sh,attributes]
----
open https://console-openshift-console.apps.${CLUSTER_DOMAIN}/dev-monitoring/ns/${PROJECT_NAME}/metrics
----

[#round-9]
== Round 9 - Sending out an SOS

We want do trigger an alert if the number of errors in a minute is greater than 4. Let's create a `PrometheusRule` to do so.

From *T2*:

[source,sh,attributes]
----
oc apply -f - <<EOF
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: fruit-gateway-alert-rules
  namespace: ${PROJECT_NAME}
  labels:
    openshift.io/prometheus-rule-evaluation-scope: leaf-prometheus
spec:
  groups:
  - name: fruit-gateway-monitoring
    rules:
    - alert: too-many-accumulated-errors
      annotations:
        description: 'accumulated errors'
        summary: Too many accumulated errors
      expr: acc_errors_count_total > 4
      for: 1m
      labels:
        severity: warning
        special_type: street-java
        alert_type: custom
EOF
----

Open this link to see if the alert has been fired or not.

[source,sh,attributes]
----
open https://console-openshift-console.apps.${CLUSTER_DOMAIN}/dev-monitoring/ns/${PROJECT_NAME}/alerts
----

Notifications...

[source,sh,attributes]
----
oc apply -f - <<EOF
---
kind: Secret
apiVersion: v1
metadata:
  name: slack-webhook-secret
stringData:
  slack-webhook-url: ${SLACK_WEBHOOK}
type: Opaque
---
apiVersion: monitoring.coreos.com/v1beta1
kind: AlertmanagerConfig
metadata:
  name: fruit-gateway-routing
  namespace: ${PROJECT_NAME}
spec:
  receivers:
    - name: slack
      slackConfigs:
        - apiURL:
            key: slack-webhook-url
            name: slack-webhook-secret
          channel: '#${SLACK_CHANNEL}'
  route:
    receiver: slack
    repeatInterval: "1m"
    routes:
      - receiver: slack
EOF
----